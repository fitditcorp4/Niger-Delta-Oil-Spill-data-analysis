{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plots\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "import plotly.express as px\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "%matplotlib inline\n",
    "\n",
    "# Modelling and Forecasting\n",
    "# ==============================================================================\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "# Configuration\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = dx = pd.read_csv(r'/home/nkem/Documents/PhD_Research/allN11Oct2022.csv')\n",
    "dx['incidentdate'] = pd.to_datetime(dx['incidentdate'])\n",
    "td = dx.copy()\n",
    "dk = td.groupby([pd.Grouper(key='incidentdate', freq='M')])['estimatedqty'].agg(['sum','size'])\n",
    "dk = dk.reset_index()\n",
    "dk.rename(columns={\"sum\":\"estimatedqty\", \"size\":\"spillno\"}, inplace=True)\n",
    "\n",
    "df = dk[[\"incidentdate\",\"spillno\"]]\n",
    "df = df.set_index(\"incidentdate\")\n",
    "df = df.drop(index=\"2022-10-31\")\n",
    "\n",
    "df= df.reset_index()\n",
    "df[\"month\"] = df[\"incidentdate\"].dt.month\n",
    "df[\"year\"] = df[\"incidentdate\"].dt.year\n",
    "dt = df[[\"incidentdate\",\"spillno\",\"month\", \"year\"]]\n",
    "dt = dt.set_index(\"incidentdate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates      : 2005-01-31 00:00:00 --- 2021-03-31 00:00:00\n",
      "Validation dates : 2021-04-30 00:00:00 --- 2022-03-31 00:00:00\n",
      "Test dates       : 2022-04-30 00:00:00 --- 2022-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "end_train = '2021-03-31'\n",
    "start_val = '2021-04-30'\n",
    "end_validation = '2022-03-31'\n",
    "start_test = '2022-04-30'\n",
    "\n",
    "data_train = dt.loc[: end_train, :]\n",
    "data_val   = dt.loc[start_val:end_validation, :]\n",
    "data_test  = dt.loc[start_test:, :]\n",
    "\n",
    "print(f\"Train dates      : {data_train.index.min()} --- {data_train.index.max()}\")\n",
    "print(f\"Validation dates : {data_val.index.min()} --- {data_val.index.max()}\")\n",
    "print(f\"Test dates       : {data_test.index.min()} --- {data_test.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select exogenous variables, including those generated by one hot encoding.\n",
    "exog_variables = [column for column in data.columns\n",
    "                      if column.startswith(('year', 'month'))]\n",
    "#exog_variables.extend(['estimatedqty'])\n",
    "#print(exog_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score,mean_absolute_percentage_error\n",
    "\n",
    "# Metrics\n",
    "metrics = ['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error']\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import  random_search_forecaster\n",
    "from skforecast.model_selection import  bayesian_search_forecaster\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================= \n",
       "ForecasterAutoreg \n",
       "================= \n",
       "Regressor: LGBMRegressor(random_state=123) \n",
       "Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
       "Transformer for y: None \n",
       "Transformer for exog: None \n",
       "Window size: 24 \n",
       "Included exogenous: False \n",
       "Type of exogenous variable: None \n",
       "Exogenous variables names: None \n",
       "Training range: None \n",
       "Training index type: None \n",
       "Training index frequency: None \n",
       "Regressor parameters: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0} \n",
       "Creation date: 2022-12-13 10:03:29 \n",
       "Last fit date: None \n",
       "Skforecast version: 0.5.0 \n",
       "Python version: 3.10.6 "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(random_state=123),\n",
    "                lags = 24\n",
    "             )\n",
    "#Lags used as predictors\n",
    "lags_grid = [1,2,3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 120,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|█████████████████████████████████████| 12/12 [00:54<00:00,  4.55s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>min_child_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1]</td>\n",
       "      <td>{'n_estimators': 2915, 'max_depth': 21, 'learn...</td>\n",
       "      <td>49.401271</td>\n",
       "      <td>6.058492</td>\n",
       "      <td>0.253865</td>\n",
       "      <td>2915.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.072058</td>\n",
       "      <td>0.032805</td>\n",
       "      <td>0.471559</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>662.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 4249, 'max_depth': 73, 'learn...</td>\n",
       "      <td>53.079062</td>\n",
       "      <td>6.341195</td>\n",
       "      <td>0.288627</td>\n",
       "      <td>4249.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.061491</td>\n",
       "      <td>0.775842</td>\n",
       "      <td>0.019581</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>624.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1]</td>\n",
       "      <td>{'n_estimators': 4249, 'max_depth': 73, 'learn...</td>\n",
       "      <td>59.250935</td>\n",
       "      <td>6.279003</td>\n",
       "      <td>0.259402</td>\n",
       "      <td>4249.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.061491</td>\n",
       "      <td>0.775842</td>\n",
       "      <td>0.019581</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>624.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 4249, 'max_depth': 73, 'learn...</td>\n",
       "      <td>60.120549</td>\n",
       "      <td>6.404949</td>\n",
       "      <td>0.265478</td>\n",
       "      <td>4249.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.061491</td>\n",
       "      <td>0.775842</td>\n",
       "      <td>0.019581</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>624.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 2915, 'max_depth': 21, 'learn...</td>\n",
       "      <td>87.176290</td>\n",
       "      <td>7.046878</td>\n",
       "      <td>0.338363</td>\n",
       "      <td>2915.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.072058</td>\n",
       "      <td>0.032805</td>\n",
       "      <td>0.471559</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>662.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'n_estimators': 3377, 'max_depth': 85, 'learn...</td>\n",
       "      <td>1250.233235</td>\n",
       "      <td>34.788425</td>\n",
       "      <td>1.628003</td>\n",
       "      <td>3377.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>1.134309</td>\n",
       "      <td>0.009433</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>555.0</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'n_estimators': 4627, 'max_depth': 85, 'learn...</td>\n",
       "      <td>1250.233235</td>\n",
       "      <td>34.788425</td>\n",
       "      <td>1.628003</td>\n",
       "      <td>4627.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.036382</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.016560</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'n_estimators': 3311, 'max_depth': 85, 'learn...</td>\n",
       "      <td>1250.233235</td>\n",
       "      <td>34.788425</td>\n",
       "      <td>1.628003</td>\n",
       "      <td>3311.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.055772</td>\n",
       "      <td>2.617038</td>\n",
       "      <td>0.034622</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>902.0</td>\n",
       "      <td>296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'n_estimators': 1295, 'max_depth': 57, 'learn...</td>\n",
       "      <td>1250.233235</td>\n",
       "      <td>34.788425</td>\n",
       "      <td>1.628003</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>0.037799</td>\n",
       "      <td>0.840025</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>754.0</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'n_estimators': 252, 'max_depth': 71, 'learni...</td>\n",
       "      <td>1250.233235</td>\n",
       "      <td>34.788425</td>\n",
       "      <td>1.628003</td>\n",
       "      <td>252.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.084085</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>1.330429</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        lags  \\\n",
       "9                                        [1]   \n",
       "11                                    [1, 2]   \n",
       "1                                        [1]   \n",
       "21                                 [1, 2, 3]   \n",
       "29                                 [1, 2, 3]   \n",
       "..                                       ...   \n",
       "113  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   \n",
       "114  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   \n",
       "115  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   \n",
       "116  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   \n",
       "117  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   \n",
       "\n",
       "                                                params  mean_squared_error  \\\n",
       "9    {'n_estimators': 2915, 'max_depth': 21, 'learn...           49.401271   \n",
       "11   {'n_estimators': 4249, 'max_depth': 73, 'learn...           53.079062   \n",
       "1    {'n_estimators': 4249, 'max_depth': 73, 'learn...           59.250935   \n",
       "21   {'n_estimators': 4249, 'max_depth': 73, 'learn...           60.120549   \n",
       "29   {'n_estimators': 2915, 'max_depth': 21, 'learn...           87.176290   \n",
       "..                                                 ...                 ...   \n",
       "113  {'n_estimators': 3377, 'max_depth': 85, 'learn...         1250.233235   \n",
       "114  {'n_estimators': 4627, 'max_depth': 85, 'learn...         1250.233235   \n",
       "115  {'n_estimators': 3311, 'max_depth': 85, 'learn...         1250.233235   \n",
       "116  {'n_estimators': 1295, 'max_depth': 57, 'learn...         1250.233235   \n",
       "117  {'n_estimators': 252, 'max_depth': 71, 'learni...         1250.233235   \n",
       "\n",
       "     mean_absolute_error  mean_absolute_percentage_error  n_estimators  \\\n",
       "9               6.058492                        0.253865        2915.0   \n",
       "11              6.341195                        0.288627        4249.0   \n",
       "1               6.279003                        0.259402        4249.0   \n",
       "21              6.404949                        0.265478        4249.0   \n",
       "29              7.046878                        0.338363        2915.0   \n",
       "..                   ...                             ...           ...   \n",
       "113            34.788425                        1.628003        3377.0   \n",
       "114            34.788425                        1.628003        4627.0   \n",
       "115            34.788425                        1.628003        3311.0   \n",
       "116            34.788425                        1.628003        1295.0   \n",
       "117            34.788425                        1.628003         252.0   \n",
       "\n",
       "     max_depth  learning_rate  reg_alpha  reg_lambda  colsample_bytree  \\\n",
       "9         21.0       0.072058   0.032805    0.471559               0.6   \n",
       "11        73.0       0.061491   0.775842    0.019581               0.6   \n",
       "1         73.0       0.061491   0.775842    0.019581               0.6   \n",
       "21        73.0       0.061491   0.775842    0.019581               0.6   \n",
       "29        21.0       0.072058   0.032805    0.471559               0.6   \n",
       "..         ...            ...        ...         ...               ...   \n",
       "113       85.0       0.009236   1.134309    0.009433               0.6   \n",
       "114       85.0       0.036382   0.001494    0.016560               0.5   \n",
       "115       85.0       0.055772   2.617038    0.034622               0.6   \n",
       "116       57.0       0.080890   0.037799    0.840025               0.6   \n",
       "117       71.0       0.084085   0.004611    1.330429               0.8   \n",
       "\n",
       "     subsample  num_leaves  min_child_samples  \n",
       "9          0.5       662.0               15.0  \n",
       "11         0.8       624.0               35.0  \n",
       "1          0.8       624.0               35.0  \n",
       "21         0.8       624.0               35.0  \n",
       "29         0.5       662.0               15.0  \n",
       "..         ...         ...                ...  \n",
       "113        0.7       555.0              117.0  \n",
       "114        0.8       131.0               97.0  \n",
       "115        0.5       902.0              296.0  \n",
       "116        0.7       754.0              223.0  \n",
       "117        1.0       338.0              279.0  \n",
       "\n",
       "[120 rows x 14 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regressor hyperparameters search space\n",
    "def search_space(trial):\n",
    "    search_space  = {'n_estimators'     : trial.suggest_int('n_estimators', 10, 5000),\n",
    "                     'max_depth'        : trial.suggest_int('max_depth', 1, 100),\n",
    "                     'learning_rate'    : trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "                     'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n",
    "                    'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n",
    "                    'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "                    'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "                    'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n",
    "                    'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n",
    "                    } \n",
    "    return search_space\n",
    "\n",
    "results, frozen_trial = bayesian_search_forecaster(\n",
    "                            forecaster            = forecaster,\n",
    "                            y                     = data.loc[:end_validation, 'spillno'],  #data_train = data.loc[: end_train, :]\n",
    "                            exog                  = data.loc[:end_validation, exog_variables],\n",
    "                            lags_grid             = lags_grid,\n",
    "                            search_space          = search_space,\n",
    "                            steps                 = 6,\n",
    "                            metric                = metrics,\n",
    "                            refit                 = True,\n",
    "                            initial_train_size    = len(data.loc[:end_train]),   \n",
    "                            fixed_train_size      = False,\n",
    "                            n_trials              = 10,\n",
    "                            random_state          = 123,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            engine                = 'optuna',\n",
    "                            kwargs_create_study   = {},\n",
    "                            kwargs_study_optimize = {}\n",
    "                        )\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: [484.11411038981555, 19.318060549594243, 0.5557008743680044]\n"
     ]
    }
   ],
   "source": [
    "# Backtesting\n",
    "# ==============================================================================\n",
    "metric, predictions = backtesting_forecaster(\n",
    "                            forecaster         = forecaster,\n",
    "                            y                  = data['spillno'],\n",
    "                            exog               = data[exog_variables],\n",
    "                            initial_train_size = len(data.loc[:end_validation]),\n",
    "                            fixed_train_size   = False,\n",
    "                            steps              = 6,\n",
    "                            refit              = True,\n",
    "                            metric             = metrics,\n",
    "                            verbose            = False\n",
    "                      )\n",
    "\n",
    "print(f\"Backtest error: {metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "This Forecaster instance is not fitted yet. Call `fit` with appropriate arguments before using predict.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nkem/Documents/PhD_Research/multiple_models.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/multiple_models.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Predictions\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/multiple_models.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/multiple_models.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m predictions \u001b[39m=\u001b[39m forecaster\u001b[39m.\u001b[39;49mpredict(steps\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skforecast/ForecasterAutoreg/ForecasterAutoreg.py:548\u001b[0m, in \u001b[0;36mForecasterAutoreg.predict\u001b[0;34m(self, steps, last_window, exog)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[1;32m    516\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    517\u001b[0m     steps: \u001b[39mint\u001b[39m,\n\u001b[1;32m    518\u001b[0m     last_window: Optional[pd\u001b[39m.\u001b[39mSeries]\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    519\u001b[0m     exog: Optional[Union[pd\u001b[39m.\u001b[39mSeries, pd\u001b[39m.\u001b[39mDataFrame]]\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    520\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mSeries:\n\u001b[1;32m    521\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[39m    Predict n steps ahead. It is an recursive process in which, each prediction,\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39m    is used as a predictor for the next step.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[39m        \u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     check_predict_input(\n\u001b[1;32m    549\u001b[0m         forecaster_type \u001b[39m=\u001b[39;49m \u001b[39mtype\u001b[39;49m(\u001b[39mself\u001b[39;49m),\n\u001b[1;32m    550\u001b[0m         steps           \u001b[39m=\u001b[39;49m steps,\n\u001b[1;32m    551\u001b[0m         fitted          \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitted,\n\u001b[1;32m    552\u001b[0m         included_exog   \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mincluded_exog,\n\u001b[1;32m    553\u001b[0m         index_type      \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex_type,\n\u001b[1;32m    554\u001b[0m         index_freq      \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex_freq,\n\u001b[1;32m    555\u001b[0m         window_size     \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwindow_size,\n\u001b[1;32m    556\u001b[0m         last_window     \u001b[39m=\u001b[39;49m last_window,\n\u001b[1;32m    557\u001b[0m         exog            \u001b[39m=\u001b[39;49m exog,\n\u001b[1;32m    558\u001b[0m         exog_type       \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexog_type,\n\u001b[1;32m    559\u001b[0m         exog_col_names  \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexog_col_names,\n\u001b[1;32m    560\u001b[0m         interval        \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    561\u001b[0m         max_steps       \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    562\u001b[0m         level           \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    563\u001b[0m         series_levels   \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    564\u001b[0m     ) \n\u001b[1;32m    566\u001b[0m     \u001b[39mif\u001b[39;00m exog \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    567\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(exog, pd\u001b[39m.\u001b[39mDataFrame):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skforecast/utils/utils.py:195\u001b[0m, in \u001b[0;36mcheck_predict_input\u001b[0;34m(forecaster_type, steps, fitted, included_exog, index_type, index_freq, window_size, last_window, exog, exog_type, exog_col_names, interval, max_steps, level, series_levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39mCheck all inputs of predict method. This is a helper function to validate\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39mthat inputs used in predict method match attributes of a forecaster already\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[0;32m--> 195\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    196\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mThis Forecaster instance is not fitted yet. Call `fit` with \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    197\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mappropriate arguments before using predict.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m steps \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`steps` must be integer greater than 0. Got \u001b[39m\u001b[39m{\u001b[39;00msteps\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    203\u001b[0m     )\n",
      "\u001b[0;31mException\u001b[0m: This Forecaster instance is not fitted yet. Call `fit` with appropriate arguments before using predict."
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "# ==============================================================================\n",
    "predictions = forecaster.predict(steps=6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Aug 10 2022, 11:40:04) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
