{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf, arma_order_select_ic\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import os\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from optuna import create_study\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import XGBoostPruningCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = (14, 6)  # figure size\n",
    "RS = 124  # random state\n",
    "N_JOBS = 8  # number of parallel threads\n",
    "\n",
    "# repeated K-folds\n",
    "N_SPLITS = 10\n",
    "N_REPEATS = 1\n",
    "\n",
    "# Optuna\n",
    "N_TRIALS = 100\n",
    "MULTIVARIATE = True\n",
    "\n",
    "# XGBoost\n",
    "EARLY_STOPPING_ROUNDS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = dx = pd.read_csv(r'/home/nkem/Documents/PhD_Research/allN11Oct2022.csv')\n",
    "dx['incidentdate'] = pd.to_datetime(dx['incidentdate'])\n",
    "td = dx.copy()\n",
    "dk = td.groupby([pd.Grouper(key='incidentdate', freq='M')])['estimatedqty'].agg(['sum','size'])\n",
    "dk = dk.reset_index()\n",
    "dk.rename(columns={\"sum\":\"estimatedqty\", \"size\":\"spillno\"}, inplace=True)\n",
    "\n",
    "df = dk[[\"incidentdate\",\"spillno\"]]\n",
    "df= df.reset_index()\n",
    "\n",
    "df[\"month\"] = df[\"incidentdate\"].dt.month\n",
    "df[\"year\"] = df[\"incidentdate\"].dt.year\n",
    "dt = df[[\"incidentdate\",\"month\", \"year\"]]\n",
    "#dt = dt.set_index(\"incidentdate\")\n",
    "#target = df[[\"incidentdate\",\"spillno\"]]\n",
    "\n",
    "dt = dt.set_index(\"incidentdate\")\n",
    "target = target.set_index(\"incidentdate\")\n",
    "\n",
    "#data = dt.loc[: \"2022-09-30\"]\n",
    "X_train = dt.loc[: \"2021-12-31\"]\n",
    "y_train = target.loc[: \"2021-12-31\"]\n",
    "#X_valid = dt.loc[\"2022-01-31\" : \"2022-06-30\"]\n",
    "#y_valid = target.loc[\"2022-01-31\" : \"2022-06-30\"]\n",
    "\n",
    "#X_train = X_train.values\n",
    "#y_train = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incidentdate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-31</th>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-28</th>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-30</th>\n",
       "      <td>4</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-05-31</th>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              month  year\n",
       "incidentdate             \n",
       "2005-01-31        1  2005\n",
       "2005-02-28        2  2005\n",
       "2005-03-31        3  2005\n",
       "2005-04-30        4  2005\n",
       "2005-05-31        5  2005"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(\n",
    "    trial,\n",
    "    X,\n",
    "    y,\n",
    "    random_state=22,\n",
    "    tscv =TimeSeriesSplit(n_splits=3),\n",
    "    n_repeats=2,\n",
    "    n_jobs=1,\n",
    "    early_stopping_rounds=50,\n",
    "):\n",
    "    # XGBoost parameters\n",
    "    params = {\n",
    "        \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimator\", 1, 10000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 12),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.005, 0.05),\n",
    "        \"colsample_bytree\": trial.suggest_loguniform(\"colsample_bytree\", 0.2, 0.6),\n",
    "        \"subsample\": trial.suggest_loguniform(\"subsample\", 0.4, 0.8),\n",
    "        \"alpha\": trial.suggest_loguniform(\"alpha\", 0.01, 10.0),\n",
    "        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 10.0),\n",
    "        \"gamma\": trial.suggest_loguniform(\"lambda\", 1e-8, 10.0),\n",
    "        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 10, 1000),\n",
    "        \"seed\": random_state,\n",
    "        \"n_jobs\": n_jobs,\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    pruning_callback = XGBoostPruningCallback(trial, \"validation_0-rmse\")\n",
    "    rkf = RepeatedKFold(\n",
    "        n_splits=tscv, n_repeats=n_repeats, random_state=random_state\n",
    "    )\n",
    "    X_values = X.values\n",
    "    y_values = y.values\n",
    "    y_pred = np.zeros_like(y_values)\n",
    "    for train_index, test_index in rkf.split(X_values):\n",
    "        X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n",
    "        y_A, y_B = y_values[train_index], y_values[test_index]\n",
    "        model.fit(\n",
    "            X_A,\n",
    "            y_A,\n",
    "            eval_set=[(X_B, y_B)],\n",
    "            eval_metric=\"rmse\",\n",
    "            verbose=0,\n",
    "            callbacks=[pruning_callback],\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "        )\n",
    "        y_pred[test_index] += model.predict(X_B)\n",
    "    y_pred /= n_repeats\n",
    "    return np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-23 12:29:28,925]\u001b[0m A new study created in memory with name: no-name-811b0367-0c4e-4e3a-802a-becb908b32fe\u001b[0m\n",
      "\u001b[33m[W 2022-11-23 12:29:28,929]\u001b[0m Trial 0 failed because of the following error: ValueError(\"The number of folds must be of Integral type. TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None) of type <class 'sklearn.model_selection._split.TimeSeriesSplit'> was passed.\")\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nkem/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1063080/3407224768.py\", line 4, in <lambda>\n",
      "    lambda trial: objective(\n",
      "  File \"/tmp/ipykernel_1063080/3673883636.py\", line 36, in objective\n",
      "    for train_index, test_index in rkf.split(X_values):\n",
      "  File \"/home/nkem/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py\", line 1414, in split\n",
      "    cv = self.cv(random_state=rng, shuffle=True, **self.cvargs)\n",
      "  File \"/home/nkem/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py\", line 435, in __init__\n",
      "    super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
      "  File \"/home/nkem/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py\", line 279, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: The number of folds must be of Integral type. TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None) of type <class 'sklearn.model_selection._split.TimeSeriesSplit'> was passed.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of folds must be of Integral type. TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None) of type <class 'sklearn.model_selection._split.TimeSeriesSplit'> was passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sampler \u001b[39m=\u001b[39m TPESampler(seed\u001b[39m=\u001b[39mRS, multivariate\u001b[39m=\u001b[39mMULTIVARIATE)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m study \u001b[39m=\u001b[39m create_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m, sampler\u001b[39m=\u001b[39msampler)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mlambda\u001b[39;49;00m trial: objective(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         trial,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         X_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         y_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         random_state\u001b[39m=\u001b[39;49mRS,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         n_repeats\u001b[39m=\u001b[39;49mN_REPEATS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         n_jobs\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         early_stopping_rounds\u001b[39m=\u001b[39;49mEARLY_STOPPING_ROUNDS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     ),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     n_trials\u001b[39m=\u001b[39;49mN_TRIALS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# display params\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m hp \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    393\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    397\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m     )\n\u001b[0;32m--> 400\u001b[0m _optimize(\n\u001b[1;32m    401\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    402\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    403\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    404\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    405\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    406\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    407\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    408\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    409\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    410\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m show_progress_bar:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:264\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch):\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    265\u001b[0m \u001b[39mreturn\u001b[39;00m trial\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    210\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    212\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m     value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb Cell 6\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sampler \u001b[39m=\u001b[39m TPESampler(seed\u001b[39m=\u001b[39mRS, multivariate\u001b[39m=\u001b[39mMULTIVARIATE)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m study \u001b[39m=\u001b[39m create_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m, sampler\u001b[39m=\u001b[39msampler)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m study\u001b[39m.\u001b[39moptimize(\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mlambda\u001b[39;00m trial: objective(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         trial,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         X_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         y_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         random_state\u001b[39m=\u001b[39;49mRS,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         n_repeats\u001b[39m=\u001b[39;49mN_REPEATS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         n_jobs\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         early_stopping_rounds\u001b[39m=\u001b[39;49mEARLY_STOPPING_ROUNDS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     ),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     n_trials\u001b[39m=\u001b[39mN_TRIALS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# display params\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m hp \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n",
      "\u001b[1;32m/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb Cell 6\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, X, y, random_state, tscv, n_repeats, n_jobs, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m y_values \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros_like(y_values)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m train_index, test_index \u001b[39min\u001b[39;00m rkf\u001b[39m.\u001b[39msplit(X_values):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     X_A, X_B \u001b[39m=\u001b[39m X_values[train_index, :], X_values[test_index, :]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nkem/Documents/PhD_Research/hyperparameter_tuning.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     y_A, y_B \u001b[39m=\u001b[39m y_values[train_index], y_values[test_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:1414\u001b[0m, in \u001b[0;36m_RepeatedSplits.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1411\u001b[0m rng \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m   1413\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_repeats):\n\u001b[0;32m-> 1414\u001b[0m     cv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv(random_state\u001b[39m=\u001b[39;49mrng, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcvargs)\n\u001b[1;32m   1415\u001b[0m     \u001b[39mfor\u001b[39;00m train_index, test_index \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m   1416\u001b[0m         \u001b[39myield\u001b[39;00m train_index, test_index\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:435\u001b[0m, in \u001b[0;36mKFold.__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, \u001b[39m*\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 435\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(n_splits\u001b[39m=\u001b[39;49mn_splits, shuffle\u001b[39m=\u001b[39;49mshuffle, random_state\u001b[39m=\u001b[39;49mrandom_state)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:279\u001b[0m, in \u001b[0;36m_BaseKFold.__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39m@abstractmethod\u001b[39m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, n_splits, \u001b[39m*\u001b[39m, shuffle, random_state):\n\u001b[1;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(n_splits, numbers\u001b[39m.\u001b[39mIntegral):\n\u001b[0;32m--> 279\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe number of folds must be of Integral type. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m of type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m was passed.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_splits, \u001b[39mtype\u001b[39m(n_splits))\n\u001b[1;32m    282\u001b[0m         )\n\u001b[1;32m    283\u001b[0m     n_splits \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_splits)\n\u001b[1;32m    285\u001b[0m     \u001b[39mif\u001b[39;00m n_splits \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: The number of folds must be of Integral type. TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None) of type <class 'sklearn.model_selection._split.TimeSeriesSplit'> was passed."
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed=RS, multivariate=MULTIVARIATE)\n",
    "study = create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(\n",
    "    lambda trial: objective(\n",
    "        trial,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        random_state=RS,\n",
    "        n_repeats=N_REPEATS,\n",
    "        n_jobs=8,\n",
    "        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "    ),\n",
    "    n_trials=N_TRIALS,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "# display params\n",
    "hp = study.best_params\n",
    "for key, value in hp.items():\n",
    "    print(f\"{key:>20s} : {value}\")\n",
    "print(f\"{'best objective value':>20s} : {study.best_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
